{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fabc241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b260c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "origin_dir = './data_origin/'\n",
    "aug_dir = './data_aug/'\n",
    "aug_method = 'ChatGPT-o4-instructed_v2'\n",
    "\n",
    "sampling_interval = 0.15  # s/frame\n",
    "tolerance = 0.15\n",
    "\n",
    "def find_pair_dirs(base_dir: str, aug_method: str=None):\n",
    "    sequence_dir = os.path.join(base_dir, aug_method, \"sequence\") if aug_method else os.path.join(base_dir, \"sequence\")\n",
    "    label_dir = os.path.join(aug_dir, aug_method, \"label\") if aug_method else os.path.join(origin_dir, \"label\")\n",
    "    os.makedirs(sequence_dir, exist_ok=True)\n",
    "    os.makedirs(label_dir, exist_ok=True)\n",
    "    return sequence_dir, label_dir\n",
    "\n",
    "origin_sequence_dir, origin_label_dir = find_pair_dirs(origin_dir)\n",
    "aug_sequence_dir, aug_label_dir = find_pair_dirs(aug_dir, aug_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a064a8b",
   "metadata": {},
   "source": [
    "# Check aug dataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4237b6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the fromat correct\n",
    "\n",
    "errors = []\n",
    "sequence_files = sorted(f for f in os.listdir(aug_sequence_dir) if f.endswith('.csv'))\n",
    "label_files = sorted(f for f in os.listdir(aug_label_dir) if f.endswith('.csv'))\n",
    "\n",
    "for seq_file in sequence_files:\n",
    "    base = os.path.splitext(seq_file)[0]\n",
    "    label_file = f\"{base}_label.csv\"\n",
    "\n",
    "    seq_path = os.path.join(aug_sequence_dir, seq_file)\n",
    "    label_path = os.path.join(aug_label_dir, label_file)\n",
    "\n",
    "    # check if label exist\n",
    "    if not os.path.exists(label_path):\n",
    "        errors.append(f\"Label file missing for {seq_file}\")\n",
    "        continue\n",
    "\n",
    "    # check sequence format\n",
    "    try:\n",
    "        df_seq = pd.read_csv(seq_path)\n",
    "        if df_seq.shape[1] != 3:\n",
    "            errors.append(f\"{seq_file} should have 3 columns, found {df_seq.shape[1]}\")\n",
    "        if df_seq.isnull().any().any():\n",
    "            errors.append(f\"{seq_file} contains NaN values\")\n",
    "    except Exception as e:\n",
    "        errors.append(f\"Failed to read {seq_file}: {e}\")\n",
    "\n",
    "    # check label format\n",
    "    try:\n",
    "        df_label = pd.read_csv(label_path)\n",
    "        expected_cols = ['gender', 'age', 'action', 'dur']\n",
    "        if list(df_label.columns) != expected_cols:\n",
    "            errors.append(f\"{label_file} header mismatch. Expected {expected_cols}, got {list(df_label.columns)}\")\n",
    "        if df_label.shape[0] != 1:\n",
    "            errors.append(f\"{label_file} should contain exactly 1 row, found {df_label.shape[0]}\")\n",
    "    except Exception as e:\n",
    "        errors.append(f\"Failed to read {label_file}: {e}\")\n",
    "if errors:\n",
    "    print(\"\\n\".join(errors))\n",
    "else:\n",
    "    print(\"All files passed the format check.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bf6719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the duration plausible\n",
    "\n",
    "errors = []\n",
    "for filename in sorted(os.listdir(aug_sequence_dir)):\n",
    "    if not filename.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    base_id = os.path.splitext(filename)[0]  # A00001\n",
    "    sequence_path = os.path.join(aug_sequence_dir, filename)\n",
    "    label_path = os.path.join(aug_label_dir, f\"{base_id}_label.csv\")\n",
    "\n",
    "    try:\n",
    "        seq_df = pd.read_csv(sequence_path)\n",
    "        label_df = pd.read_csv(label_path)\n",
    "\n",
    "        num_frames = len(seq_df)\n",
    "        duration = float(label_df.iloc[0]['dur'])\n",
    "\n",
    "        expected_duration = num_frames * sampling_interval\n",
    "        delta = abs(expected_duration - duration)\n",
    "\n",
    "        if delta > tolerance:\n",
    "            errors.append((base_id, num_frames, duration, expected_duration, delta))\n",
    "    except Exception as e:\n",
    "        print(f\"can't load data of {base_id}: {e}\")\n",
    "\n",
    "if errors:\n",
    "    print(\"These files' duration in label is implausible：\")\n",
    "    for base_id, frames, label_dur, expected_dur, delta in errors:\n",
    "        print(f\" - {base_id}: num_frames={frames}, duration={label_dur:.2f}s, expexted duration={expected_dur:.2f}s, delta={delta:.2f}s\")\n",
    "else:\n",
    "    print(\"All duration in labels are plausible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb011e2f",
   "metadata": {},
   "source": [
    "# Check feature action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7df9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect action classes in labels\n",
    "\n",
    "def collect_action_classes(label_root):\n",
    "    all_actions = set()\n",
    "    for filename in sorted(os.listdir(label_root)):\n",
    "        if filename.endswith('.csv'):\n",
    "            filepath = os.path.join(label_root, filename)\n",
    "            try:\n",
    "                df = pd.read_csv(filepath)\n",
    "                if 'action' not in df.columns:\n",
    "                    print(f\"no action feature for {filename}\")\n",
    "                    continue\n",
    "                actions = df['action'].dropna().unique()\n",
    "                all_actions.update(actions)\n",
    "            except Exception as e:\n",
    "                print(f\"fail to load {filename}: {e}\")\n",
    "    return sorted(list(all_actions))\n",
    "\n",
    "original_actions = collect_action_classes(origin_label_dir)\n",
    "augmented_actions = collect_action_classes(aug_label_dir)\n",
    "\n",
    "print(\"in origin dataset：\", original_actions)\n",
    "print(\"in augmented dataset：\", augmented_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adf0fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect num of data sample for specific action class\n",
    "target_action = 'crawl' \n",
    "\n",
    "matched_filenames = []\n",
    "for filename in sorted(os.listdir(origin_label_dir)):\n",
    "    if filename.endswith('_label.csv'):\n",
    "        filepath = os.path.join(origin_label_dir, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "\n",
    "        if target_action in df['action'].values:\n",
    "            file_id = filename.replace('_label.csv', '')\n",
    "            matched_filenames.append(file_id)\n",
    "\n",
    "print(f\"finded out {len(matched_filenames)} samples for action class '{target_action}':\")\n",
    "print(matched_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684af1e1",
   "metadata": {},
   "source": [
    "# Generate the user prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2a614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "target_action = 'crawl'\n",
    "explanation = '婴儿在地板上爬行'\n",
    "\n",
    "train_txt_path = './data_origin/train.txt'\n",
    "with open(train_txt_path, 'r') as f:\n",
    "    train_ids = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "result_list = []\n",
    "for seq_id in train_ids:\n",
    "    label_path = os.path.join(origin_label_dir, f'{seq_id}_label.csv')\n",
    "    seq_path = os.path.join(origin_sequence_dir, f'{seq_id}.csv')\n",
    "\n",
    "    if not os.path.exists(label_path) or not os.path.exists(seq_path):\n",
    "        continue\n",
    "\n",
    "    label_df = pd.read_csv(label_path)\n",
    "    if 'action' not in label_df.columns or label_df.iloc[0]['action'] != target_action:\n",
    "        continue\n",
    "\n",
    "    data_df = pd.read_csv(seq_path)\n",
    "    if not all(col in data_df.columns for col in ['accel_x', 'accel_y', 'accel_z']):\n",
    "        continue\n",
    "\n",
    "    # calculate mean and std\n",
    "    mean_series = data_df.mean()\n",
    "    std_series = data_df.std()\n",
    "\n",
    "    sample_stat = {\n",
    "        \"id\": seq_id,\n",
    "        \"accel_x\": f\"{mean_series['accel_x']:.9f}±{std_series['accel_x']:.9f}\",\n",
    "        \"accel_y\": f\"{mean_series['accel_y']:.9f}±{std_series['accel_y']:.9f}\",\n",
    "        \"accel_z\": f\"{mean_series['accel_z']:.9f}±{std_series['accel_z']:.9f}\"\n",
    "    }\n",
    "\n",
    "    result_list.append(sample_stat)\n",
    "\n",
    "# 打印\n",
    "print(f\"(1)模拟动作：{explanation}(action=\\\"{target_action}\\\")\")\n",
    "print(f\"(2)统计数据：\\n{json.dumps(result_list[:], indent=2, ensure_ascii=False)}\")\n",
    "print(\"请参考以上信息生成符合要求的数据。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eb36b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_blank_csv_files(aug_sequence_dir, aug_label_dir, num_files=150):\n",
    "    # check max number existed\n",
    "    existing_files = [\n",
    "        f for f in os.listdir(aug_sequence_dir) if f.startswith(\"A\") and f.endswith(\".csv\")\n",
    "    ]\n",
    "    max_index = (\n",
    "        max([int(f[1:6]) for f in existing_files]) + 1 if existing_files else 0\n",
    "    )\n",
    "\n",
    "    for i in range(num_files):\n",
    "        file_id = f\"A{max_index + i:05d}\"\n",
    "        sequence_path = os.path.join(aug_sequence_dir, f\"{file_id}.csv\")\n",
    "        label_path = os.path.join(aug_label_dir, f\"{file_id}_label.csv\")\n",
    "        \n",
    "        if not os.path.exists(sequence_path):\n",
    "            with open(sequence_path, 'w') as f:\n",
    "                pass\n",
    "        if not os.path.exists(label_path):\n",
    "            with open(label_path, 'w') as f:\n",
    "                pass\n",
    "\n",
    "    print(f\"✅ have generated {num_files} blank file pairs:\\nfrom A{max_index:05d} to A{max_index + num_files - 1:05d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde6b124",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_blank_csv_files(aug_sequence_dir, aug_label_dir, num_files=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
